FORWARD
The DAC Working Party on Aid Evaluation (WP-EV) has developed this glossary on key terms in evaluation and results-based management because of the need to reduce terminological confusion always encountered in these areas. 
Evaluation is a field where development partners---often with widely differing linguistic backgrounds--- work together and need to use common vocabulary. 
Over the years, however, definitions evolved in such a way that they bristled with a faux amis, ambivalence and ambiguity. 
It had become urgent to clarify and refine the language employed and to give it a harmonious, common basis. 
With this publication, the (WP-EV) hopes to facilitate and improve dialogue and understanding among all those who are involved in development activities and their evaluation, whether in partner countries, development agencies and banks, or non-governmental organizations.
 It should serve as a valuable reference guide in evaluation training and in practical development work.
The selection of terms and their definitions in the attached glossary have been carefully discussed and analyzed and have benefited from advice and inputs, notably from DAC members and the academic evaluation community. 
WP-EV Task Force, chaired by the World Bank, led the overall project, in collaboration with the secretariat. 
France took lead with the French version, while the Inter-American Development Bank produced the Spanish translation. 
Denmark, the Netherlands, UNDP provided financial support for the initial collection and review work, and Switzerland contributed financial support for producing this free distribution publication. 
The process has been guided by the highest considerations of clarity and conciseness and a spirit of collaboration and compromise in terms of the willingness of major development agencies and banks not to impose their specific vocabulary on others. 
Although terminology will continue to develop alongside changing development practices and management instruments, this glossary is a “state-of-the-art” of key terms in use today.
Niels Dabelstein
Chair of the Working Party on Aid Evaluation          
FORWARD BY KENYA EVALUATION ASSOCIATION (KEA)
The translation of key terms used in aid evaluation and results based management into Kiswahili is motivated by the fact that Kiswahili is used widely across the vast region of East, Central and parts of Southern African countries (ECSAC), where virtually all the countries in this region are beneficiaries of development aid. 
Development evaluation and the politics of aid have aroused interest among a variety of stakeholders: aid agencies, civil society, community based organizations (CBO), government agencies and departments, academic institutions, the media and the private sector. 
Although European languages have been dominant in aid administration and evaluation until now, there is evidence that Kiswahili is claiming its rightful place as the lingua franca, national and official language in many countries in Africa. It is widely used as a language of communication by community groups, NGO’s and local government officials active in development planning, implementation and evaluation.
 It is important, therefore, to avail at the earliest opportunity this standardized terminology that is currently used by international development partners and evaluators. 
Kenya Evaluation Association founded in 1999, is proud to spearhead this Kiswahili version of the GLOSSARY. 
The process has benefited from inputs from a wide range of stakeholders. 
Among these is Dr. Omboga Zaja who translated the terms from English into Kiswahili and a select panel of experts comprising KEA members, evaluation practitioners and development scholars from regional universities who ratified the translations at a workshop held on the 17th to 19th November 2005.
The Kenya Evaluation Association would like to thank the OECD/DAC Network on Development Evaluation for funding the translation and publication of this glossary.  
FORWARD BY DAC NETWORK ON DEVELOPMENT EVALUATION
The publication of the Kiswahili version of the Glossary of Key Terms in Evaluation and Results Based Management is an important development which will contribute to strengthening the use and quality of evaluation and will facilitate communication among evaluation experts and with non evaluation practitioners.
We would like to express our thanks to the Kenyan Evaluation Association, and its Chair Dr. Karen Odhiambo for taking this initiative and producing a Kiswahili version of the glossary. 
This complements the other existing language versions of the glossary, which are available on the network of the DAC Evaluation Network.
Eva Litman—Chair
Hans E. Lundgren—Co-ordinator
www.oecd.org/dac/evaluationnetwork
The Development Assistance Committee (DAC) Working Party on Aid Evaluation is an international forum where bilateral and multilateral development evaluation experts meet periodically to share experience and improve evaluation practice and strengthen its use as an instrument for development co-operation policy. 
It operates under the aegis of the DAC and presently consists of 30 representatives from OECD member countries and multilateral agencies [Australia, Austria, Belgium, Canada, Denmark, European Commission, Finland, France, Germany, Greece, Ireland, Italy, Japan, Luxembourg, Netherlands, New Zealand, Norway, Portugal, Spain, Sweden, Switzerland, United Kingdom, United States, World Bank, Asian Development Bank, African Development Bank, Inter-American Development Bank, UN Development Programme, International Monetary Fund]. Further information may be obtained from Hans Lundgren, Advisor on Aid Effectiveness, OECD, Development Co-operation Directorate, 2 rue Andre-Pascal, 75775 Paris Cedex 16, France. Website: www.oecd.org/dac/evaluation
GLOSSARY OF KEY TERMS IN EVALUATION AND RESULTS BASED MANAGEMENT
TERMS GRUOPED BY CATEGORIES
QUALITY ASSURANCE
Appraisal
Audit
Conclusions
Evaluability
Evaluation
Feedback
Finding
Monitoring
Lessons learned
Performance measurement
Quality Assurance
Recommendations
Results Based Management
STAKEHOLDERS
Beneficiaries
Partners
Reach
Stakeholders
Target Group
LOGICAL FRAMEWORK
Activity
Assumptions
Development objective
Logical Framework
RESULTS-BASED MANAGEMENT
Benchmark
Inputs
Outcome
Outputs
Indicator
Performance
Performance Indicator
Performance Measurement
Project or program objective
Purpose
Results
Results chain
Results Framework
Results-based Management
EVALUATION TOOLS, MEASURES, ANALYSES AND CRITERIA
Accountability
Analytical tools
Attribution
Base-line Study
Counterfactual
Data collection tools
Development Intervention
Economy
Effect
Effectiveness
Efficiency
Feedback
Goal
Impacts
Institutional Development Impact
Lessons Learnt
Reach
Relevance
Terms of reference
Triangulation
Validity
TYPES OF EVALUATION
Cluster Evaluation
Country Program Evaluation/
Country Assistance Evaluation
Ex-ante evaluation
Ex-post Evaluation
External Evaluation
Formative Evaluation
Independent Evaluation
Internal Evaluation
Joint Evaluation
Mid-term Evaluation
Participatory Evaluation
Process Evaluation
Program Evaluation
Project Evaluation
Review
Risk Analysis
Sector Program Evaluation
Self-evaluation
Summative Evaluation
Thematic Evaluation
Accountability
Obligation to demonstrate that work has been conducted in compliance with agreed rules and standards or to report fairly and accurately on performance results vis a vis mandated roles and/or plans. 
This may require a careful, even legally defensible, demonstration that the work is consistent with contract terms.
Note: Accountability in development may refer to the obligations of partners to act according to clearly defined responsibilities, roles and performance expectations, often with respect to prudent use of resources. 
For evaluators, it connotes the responsibility to provide accurate, fair and credible monitoring reports and performance assessments. For public sector managers and policy-makers, accountability is to taxpayers/citizens.
Activity
Actions taken or work performed through which inputs, such as funds, technical assistance and other types of resources are mobilized to produce specific outputs.
Related term: development intervention.
Analytical tools
Methods used to process and interpret information during evaluation.
Appraisal
An overall assessment of the relevance, feasibility and potential sustainability of a development intervention prior to a decision of funding.
Note: In development agencies, banks, etc., the purpose of appraisal is to enable decision-makers to decide whether the activity presents an appropriate use of corporate resources.
Related term: Ex-ante evaluation.
Assumptions
Hypotheses about factors or risks which could affect the progress or success of a development intervention.
Note: Assumptions can also be understood as hypothesized conditions that bear on the validity of the evaluation itself, e.g., about the characteristics of the population when designing a sampling procedure for a survey. 
Assumptions are made explicit in theory based evaluations where evaluation tracks systematically the anticipated results chain.
Attribution (Imputation)
The ascription of a casual link between observed (or expected to be observed) changes and a specific intervention.
Note: Attribution refers to that which is to be credited for the observed changes or results achieved. It represents the extent to which observed developments effects can be attributed to a specific intervention or to the performance of one or more partners taking account of other interventions (anticipated or unanticipated) confounding factors, or external shocks.
Audit
An independent, objective assurance activity designed to add value and improve an organization’s operations. 
It helps an organization accomplish its objectives by being a systematic, disciplined approach to assess and improve the effectiveness of risk management, control and governance processes.
Note: A distinction is made between regularity (financial) auditing, which focuses on compliance with applicable statutes and regulations; and performance auditing; which is concerned with relevance, economy, efficiency and effectiveness. 
Internal auditing provides an assessment of internal controls undertaken by a unit reporting to management while external auditing is conducted by an independent organization.
Benchmark
A reference point or standard against which performance or achievement can be assessed.
Note: A benchmark refers to the performance that has been achieved in the recent past by other comparable organizations, or what can reasonably be inferred to have been achieved in the circumstances. 
Base-Line Study
An analysis describing the situation prior to a development intervention, against which progress can be assessed or comparisons made.
Beneficiaries
The individuals, groups, or organizations, whether targeted or not, that benefit directly or indirectly from development intervention.
Cluster Evaluation 
An evaluation of a set of related activities, projects and/or programs.
Conclusions
Conclusions point out the factors of a success and failure of the evaluated intervention, with special attention paid to the intended and unintended results and impacts, and more generally to any other strength or weakness. 
A conclusion draws on data collection and analyses undertaken, through a transparent chain of arguments.
Counterfactual
The situation or conditions which hypothetically may prevail for individuals, organizations, or groups were there no development intervention.
Development Intervention
An instrument for partner (donor and non-donor) support aimed to promote development.
Country Program Evaluation/
Country Assistance Evaluation
Evaluation of one or more donor’s or agency’s portfolio of development intervention, and the assistance strategy behind them, in a partner country.
Data Collection Tools
Methodologies used to identify information sources and collect information during an evaluation.
Development Objective
Intended impact contributing to physical, financial, institutional, social, environmental, or other benefits to a society, community, or group of people via one or more development interventions.
Economy 
Absence of waste for a given output.
Note: An activity is economical when the costs of the scarce resources used approximate the minimum needed to achieve planned objectives.
Effectiveness
The extent to which the development intervention’s objectives were achieved, or are expected to be achieved, taking into account their relative importance.
Note: Also used as an aggregate measure (or judgment about) the merit or worth of an activity, i.e. the extent to which an intervention has attained, or is expected to attain, its major relevant objectives efficiently in a sustainable fashion and with a positive institutional development impact.
Efficiency
A measure of how economically resources/inputs (funds, expertise, time, etc.) are converted into results.
Effect
Intended or unintended change due directly or indirectly to an intervention.
Related Terms: results, outcome.
Evaluability
Extent to which an activity or a program can be evaluated in a reliable and credible fashion.
Note: Evaluability assessment calls for the early review of a proposed activity in order to ascertain whether its objectives are adequately defined and its results verifiable.
Evaluation
The systematic and objective assessment of an on-going or completed project, program or policy, its design, implementation and results. 
The aim is to determine the relevance and fulfillment of objectives, development efficiency, effectiveness, impact and sustainability.
 An evaluation should provide information that is credible and useful, enabling the incorporation of lessons learned into the decision-making processes for both recipients and donors. 
Evaluation also refers to the processes of determining the worth or significance of an activity, policy or program. An assessment, as systematic and objective as possible, of a planned, on-going, or completed development intervention.
Note: Evaluation in some instances involves the definition of appropriate standards, the examination of performance against those standards, an assessment of actual and expected results and the identification of lessons.
Related Term: review.
Ex-ante Evaluation
An evaluation that is performed before implementation of a development intervention.
Ex-post Evaluation
Evaluation of a development intervention after it has been completed.
Note: It may be undertaken directly after or long after completion. 
The intention is to identify the factors of success or failure, to assess the sustainability of results and impacts, and to draw conclusions that may inform other interventions.
External Evaluation
The evaluation of a development intervention conducted by entities and/or individuals outside the donor and implementation organizations.
Formative Evaluation
Evaluation intended to improve performance, most often conducted during the implementation phase of projects or programs.
Note: Formative evaluations may also be conducted for other reasons such as compliance, legal requirements or as part of a larger evaluation initiative.
Related Term: process evaluation.
Feedback
The transmission of findings generated through the evaluation process to parties for whom it is relevant and useful so as to facilitate learning. 
This may involve the collection and dissemination of findings, conclusions, recommendations and lessons from experience.
Goal
The higher-order objective to which a development intervention is intended to contribute. 
Related Term: development objective.
Independent Evaluation
An evaluation carried out by entities and persons free of the control of those responsible for the design and implementation of the development intervention.
Note: The credibility of an evaluation depends in part on how independently it has been carried out. 
Independence implies freedom from political influence and organizational pressure.
Impacts
Positive and negative, primary and secondary long-term effects produced by a development intervention, directly or indirectly, intended or unintended.
Indicator
Quantitative or qualitative factor or variable that provides a simple and reliable means to measure achievement, reflect the changes connected to an intervention, or to help assess the performance of a development actor.
Inputs
The financial, human, and material resources used for the development intervention.
Institutional Development Impact
The extent to which an intervention improves or weakens the ability of a country or region to make more efficient, equitable, and sustainable use of its human, financial and natural resources, for example: 
(a) better definition, stability, transparency, enforceability and predictability of institutional arrangements and/or 
(b) better alignment of the mission and capacity of an organization with its mandate, which derives from these institutional arrangements. 
Such impacts can include intended and unintended effects of an action.
Internal Evaluation
Evaluation of a development intervention conducted by a unit and/or individuals reporting to the management of the donor, partner, or implementing organization. 
Related Term: self-evaluation.
Joint Evaluation
An evaluation to which different donor agencies and/or partners participate.
Note: There are various degrees of “jointness” depending on the extent to which individual partners cooperate in the evaluation process, merge their evaluation resources and combine their evaluation reporting. 
Joint evaluation can help overcome attribution problems in assessing the effectiveness of programs and strategies, the complementarity of efforts supported by different partners, the quality of aid coordination, etc.
Lessons Learned 
Generalizations based on evaluation experiences with projects, programs, or policies that abstract from the specific circumstances to broader situations. 
Frequently, lessons highlight strengths or weaknesses in preparation, design, and implementation that affect performance, outcome, and impact.
Logical Framework (Logframe) 
Management tool used to improve the design of interventions, most often at the project level. 
It involves identifying strategic elements (inputs, outputs, outcomes, impact) and their casual relationships, indicators, and the assumptions or risks that may influence success or failure.
 It thus facilitates planning, execution and evaluation of a development intervention.
Related Term: results based management. 
Meta-evaluation
The term is used for evaluations designed to aggregate findings from a series of evaluations. 
It can also be used to denote the evaluation of an evaluation to judge its quality and/or assess the performance of the evaluators.
Participatory Evaluation
Evaluation method in which representatives of agencies and stakeholders (including beneficiaries) work together in designing, carrying out and interpreting an evaluation.
Partners
The individuals and/or organizations that collaborate to achieve mutually agreed upon objectives.
Note: The concept of partnership connotes shared goals, common responsibility for outcomes, distinct accountabilities and reciprocal obligations. 
Partners may include governments, civil society, non-governmental organizations, universities, professional and business associations, multilateral organizations private companies, etc. 
Mid-term Evaluation
Evaluation performed towards the middle of the period of implementation of the intervention.
Monitoring
A continuing  function that uses systematic collection of data on specified indicators to provide management and the main stakeholders of an on going development intervention with indications of the extent of progress and achievement of objectives and progress in the use of allocated funds.
Related  term: performance monitoring, indicator.
Outcome
The likely or achieved short-term and medium-term effects of an intervention’s outputs.
Related Term:  result, output, impacts, effect.
Outputs
The products, capital goods and services which result from a development intervention; may also include changes resulting from the interventions which are relevant to the achievement of outcomes.
Performance
The degree to which a development intervention or a development partner operates according to specific criteria/standards/guidelines or achieves results in accordance with stated goals or plans.
Performance Indicator
A variable that allows the verification of changes in the development intervention or shows results relative to what was planned.
Related Terms: performance monitoring, performance measurement.
Performance Measurement
A system of assessing performance of development interventions against stated goals.
Related Terms: performance monitoring, indicator.
Performance Monitoring
A continuous process of collecting and analyzing data to compare how well a project, program, or policy is being implemented against expected results.
Process Evaluation
An evaluation of the internal dynamics of implementing organizations, their policy instruments, their service delivery mechanisms, their management practices and the linkages among them. 
Related Term: formative evaluation. 
Program Evaluation
Evaluation of a set of interventions, marshaled to attain a specific global, regional, country, or sector development objectives.
Note: a development program is a time bound intervention involving multiple activities that may cut across sectors, themes and/or geographical areas.
Related Term: Country program/strategy evaluation.
Project Evaluation
Evaluation of an individual development intervention designed to achieve specific objectives within specified resource and implementation schedules, often within the framework of a broader program.
Note: Cost benefit analysis is a major instrument of project evaluation for projects with measurable benefits. When benefits cannot be quantified, cost effectiveness is a suitable approach.
Project or program objective
The intended physical, financial, institutional, social, environmental, or other development results to which a project or program is expected to contribute.
Purpose
The publicly stated objectives of the development program or project.
Quality Assurance
Quality assurance encompasses any activity that is concerned with assessing and improving the merit or the worth of a development intervention or its compliance with given standards.
Note: examples of quality assurance activities include appraisal, RBM, reviews during implementation, evaluations, etc. 
Quality assurance may also refer to the assessment of the quality of a portfolio and its development effectiveness.
Recommendations
Proposals aimed at enhancing the effectiveness, quality, or efficiency of a development intervention; at redesigning the objectives; and/or at the reallocation of resources.
 Recommendations should be linked to conclusions.
Relevance
The extent to which the objectives of a development intervention are consistent with beneficiaries’ requirements, country needs, global priorities and partners’ and donors’ policies.
Note: Retrospectively, the question of relevance often becomes a question as to whether the objectives of an intervention or its design are still appropriate given changed circumstances.
Reliability
Consistency or dependability of data and evaluation judgments, with reference to the quality of the instruments, procedures and analyses used to collect and interpret evaluation data.
Note: evaluation information is reliable when repeated observations using similar instruments under similar conditions producer similar results.
Reach
The beneficiaries and other stakeholders of a development intervention.
Related Term: beneficiaries.
Results
The output, outcome or impact (intended or unintended, positive and or negative) of a development intervention.
Related Term: outcome, effect, impacts.
Results Chain
The casual sequence for a development intervention that stipulates the necessary sequence to achieve desired objectives beginning with inputs, moving through activities and outputs, and culminating in outcomes, impacts, and feedback. 
In some agencies, reach is part of the results chain.
Related Term: assumptions, results framework.
Results Framework
The program logic that explains how the development objective is to be achieved, including casual relationships underlying assumptions.
Related Term: results chain, logical framework.
Review
As assessment of the performance of an intervention, periodically or on an ad hoc basis.
Note: Frequently “evaluation” is used for a more comprehensive and/or more in-depth assessment than “review”. 
Reviews tend to emphasize operational aspects. 
Sometimes the terms “review” and “evaluation” are used as synonyms. 
Results-Based Management (RBM) 
A management strategy focusing on performance and achievements of outputs, outcomes and impacts.
Related Term: logical framework. 
Risk Analysis
An analysis or an assessment of factors (called assumptions in the logframe) that affects or is likely to affect the successful achievement of an intervention’s objectives. 
A detailed examination of the potential unwanted and negative consequences to the human life, health, property, or environment posed by development interventions;
 a systematic process to provide information regarding such undesirable consequences, the process of quantification of the probabilities and expected impacts for identified risks.
Sector Program Evaluation
Evaluation of a cluster of development interventions in a sector within one country or across countries, all of which contribute to the achievement of a specific development goal.
Note: a sector includes development activities commonly grouped together for the purpose of public action such as health, education, agriculture, transport, etc.
Self-evaluation
An evaluation by those who are entrusted with the design and delivery of a development intervention.
Stakeholders
Agencies, organizations, groups or individuals who have a direct or indirect interest in the development intervention or its evaluation.
Summative Evaluation
A study conducted at the end of an intervention (or a phase of that intervention) to determine the extent to which anticipated outcomes were produced. Summative evaluation is intended to provide information about the worth of the program.
Related Term: impact evaluation.
Sustainability
The continuation of benefits from a development intervention after major development assistance has been completed. 
The probability of continued long-term benefits. 
The resilience to risk of the net benefits flows over time.
Target Group
The specific individuals or organizations for whose benefit the development is undertaken.
Terms of Reference
Written documents presenting the purpose and the scope of the evaluation, the methods to used, the standard against which performance is to assessed or analyses are conducted, the resources and time allocated, and reporting requirements. 
Two other expressions sometimes used with the same meaning are “scope of work” and “evaluation mandate”.
Thematic Evaluation
Evaluation of a selection of development interventions, all of which address a specific development priority that cuts across countries, regions and sectors.

Triangulation
The use of three or more theories, sources or types of information, or types of analysis to verify and substantiate assessment.
Note: by combining multiple data-sources, methods, analyses or theories, evaluators seek to overcome the bias that comes from single informants, single-methods, single observer or single theory studies.
Validity 
The extent to which the data collection strategies and instruments measure what they purport to measure.
